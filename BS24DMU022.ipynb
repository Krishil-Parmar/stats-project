{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44149dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# housing_regression.py\n",
    "# A complete linear regression for the housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d512a2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0134748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load the dataset\n",
    "df = pd.read_csv('housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b0bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Initial inspection & cleaning\n",
    "print(\"=== First five rows ===\")\n",
    "print(df.head(), \"\\n\")\n",
    "\n",
    "print(\"=== Data summary (numeric columns) ===\")\n",
    "print(df.describe().T, \"\\n\")\n",
    "\n",
    "print(\"=== Missing values per column ===\")\n",
    "print(df.isnull().sum(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb10603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1 – Barplot of missing values before imputation\n",
    "# ------------------------------------------------------\n",
    "# Run this *before* the median fill step.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Count NaNs column-wise\n",
    "na_counts = df.isnull().sum()\n",
    "na_counts = na_counts[na_counts > 0].sort_values() \n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(\n",
    "    x=na_counts.values,\n",
    "    y=na_counts.index,\n",
    "    palette=\"crest\",\n",
    "    orient=\"h\"\n",
    ")\n",
    "plt.title(\"Missing Values per Column (Pre-Imputation)\")\n",
    "plt.xlabel(\"Number of Missing Entries\")\n",
    "plt.ylabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb602e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Categorical encoding – one‑hot for ocean_proximity (required for OLS)\n",
    "if \"ocean_proximity\" in df.columns:\n",
    "    df = pd.get_dummies(df, columns=[\"ocean_proximity\"], drop_first=True)\n",
    "else:\n",
    "    print(\"Note: 'ocean_proximity' already one‑hot encoded – skipping get_dummies.\")\n",
    "\n",
    "missing_total = df.isnull().sum().sum()\n",
    "if missing_total > 0:\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n",
    "    print(f\"Imputed {missing_total} missing numeric values with column medians.\")\n",
    "else:\n",
    "    print(\"No missing numeric values to impute.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbef0890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Exploratory Data Analysis (EDA) ───────────────────────────────────────\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b184759f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Histograms\n",
    "_ = df[numeric_cols].hist(figsize=(14, 10), bins=30)\n",
    "plt.suptitle(\"Histograms of Numeric Features\", y=1.02, fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09133eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Boxplots\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.boxplot(data=df[numeric_cols], orient=\"h\", palette=\"vlag\")\n",
    "plt.title(\"Boxplots of Numeric Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b9f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Correlation heatmap\n",
    "plt.figure(figsize=(12, 9))\n",
    "corr = df[numeric_cols].corr()\n",
    "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e9a258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Outlier detection (report only, no removal) ───────────────────────────\n",
    "Z = np.abs(stats.zscore(df[numeric_cols]))\n",
    "outlier_mask = (Z >= 3).any(axis=1)\n",
    "print(f\"Rows with |Z| ≥ 3: {outlier_mask.sum()} (reported, not removed)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62702e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Train‑test split ──────────────────────────────────────────────────────\n",
    "TARGET = \"median_house_value\"\n",
    "X = df.drop(TARGET, axis=1)\n",
    "y = df[TARGET]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f721692",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regression equation \n",
    "\n",
    "coef_series = pd.Series(linreg.coef_, index=X.columns)\n",
    "eqn = \"median_house_value = \" + \" + \".join(\n",
    "    f\"{b:.4f}*{c}\" for c, b in coef_series.items()\n",
    ") + f\" + {linreg.intercept_:.4f}\"\n",
    "print(\"\\nRegression equation:\\n\", eqn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c46a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 scikit‑learn fit\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "y_pred = linreg.predict(X_test)\n",
    "\n",
    "# 7.2 statsmodels OLS for detailed stats\n",
    "X_train_sm = sm.add_constant(X_train).astype(float)\n",
    "# Ensure y is float\n",
    "y_train_float = y_train.astype(float)\n",
    "ols_model = sm.OLS(y_train_float, X_train_sm).fit()\n",
    "print(ols_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984bf6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Diagnostics ───────────────────────────────────────────────────────────\n",
    "# 8.1 VIF\n",
    "vif = pd.DataFrame({\n",
    "    \"feature\": X_train_sm.columns,\n",
    "    \"VIF\": [variance_inflation_factor(X_train_sm.values, i) for i in range(X_train_sm.shape[1])]\n",
    "})\n",
    "print(\"\\n=== Variance Inflation Factors ===\")\n",
    "print(vif, \"\\n\")\n",
    "\n",
    "# 8.2 Residual analysis\n",
    "residuals = y_train_float - ols_model.predict(X_train_sm)\n",
    "\n",
    "# Histogram\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title(\"Residuals Distribution\")\n",
    "plt.show()\n",
    "\n",
    "# Q-Q plot\n",
    "sm.qqplot(residuals, line=\"45\", fit=True)\n",
    "plt.title(\"Q-Q Plot of Residuals\")\n",
    "plt.show()\n",
    "\n",
    "# Residuals vs fitted\n",
    "plt.scatter(ols_model.predict(X_train_sm), residuals, alpha=0.5)\n",
    "plt.axhline(0, color=\"red\", ls=\"--\")\n",
    "plt.xlabel(\"Fitted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residuals vs. Fitted\")\n",
    "plt.show()\n",
    "\n",
    "# Normality & autocorrelation tests\n",
    "sh_w, sh_p = stats.shapiro(residuals)\n",
    "dw = sm.stats.stattools.durbin_watson(residuals)\n",
    "print(f\"Shapiro‑Wilk: W = {sh_w:.3f}, p = {sh_p:.4f}\")\n",
    "print(f\"Durbin‑Watson : {dw:.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e149b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# --- 1.  Make column names safe for patsy (no spaces or punctuation) ---\n",
    "safe_cols = {c: c.replace(\" \", \"_\").replace(\">\", \"gt\") for c in df.columns}\n",
    "df_ren = df.rename(columns=safe_cols)\n",
    "\n",
    "# --- 2.  Build formula string ---\n",
    "TARGET = \"median_house_value\"\n",
    "predictors = [c for c in df_ren.columns if c != TARGET]\n",
    "formula = TARGET + \" ~ \" + \" + \".join(predictors)\n",
    "\n",
    "# --- 3.  Fit formula-based OLS on *training* rows only (to keep parity) ---\n",
    "train_idx = X_train.index                    # same rows used earlier\n",
    "ols_formula = smf.ols(formula, data=df_ren.loc[train_idx]).fit()\n",
    "\n",
    "# --- 4.  Print summary (optional) ---\n",
    "print(ols_formula.summary())\n",
    "\n",
    "# --- 5.  Type-II ANOVA table (matches sample report) ---\n",
    "anova_tbl = anova_lm(ols_formula, typ=2)\n",
    "print(\"\\n=== ANOVA Table (Type II) ===\\n\", anova_tbl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83649ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Type-II ANOVA on the training data -----------------------------------\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# 1) Make column names patsy-safe (replace spaces, symbols)\n",
    "safe_map = {c: c.replace(\" \", \"_\").replace(\"<\", \"lt\").replace(\">\", \"gt\")\n",
    "            for c in df.columns}\n",
    "df_safe   = df.rename(columns=safe_map)\n",
    "\n",
    "# 2) Build formula string:  median_house_value ~ all other columns\n",
    "TARGET = \"median_house_value\"\n",
    "predictors = [c for c in df_safe.columns if c != TARGET]\n",
    "formula = TARGET + \" ~ \" + \" + \".join(predictors)\n",
    "\n",
    "# 3) Fit formula OLS **on training rows only**\n",
    "train_idx   = X_train.index              # reuse earlier split\n",
    "ols_formula = smf.ols(formula, data=df_safe.loc[train_idx]).fit()\n",
    "\n",
    "# 4) Type-II sums of squares\n",
    "anova_tbl = anova_lm(ols_formula, typ=2)   # columns: DF, sum_sq, F, PR(>F)\n",
    "print(\"\\n=== Type-II ANOVA Table ===\\n\")\n",
    "print(anova_tbl.round(2))                  # <-- Table 4 for the report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95762207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "#  A)   Drop 'latitude' before VIF analysis\n",
    "# ------------------------------------------\n",
    "X_vif = X_train.drop(columns=['latitude'])   # keep longitude as proxy\n",
    "\n",
    "# Cast to float\n",
    "X_vif = X_vif.astype(float)\n",
    "\n",
    "vif_df = pd.DataFrame({\n",
    "    'feature': X_vif.columns,\n",
    "    'VIF': [variance_inflation_factor(X_vif.values, i)\n",
    "            for i in range(X_vif.shape[1])]\n",
    "})\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=vif_df.sort_values('VIF', ascending=False),\n",
    "            x='VIF', y='feature', palette='mako')\n",
    "plt.title('Variance Inflation Factors (latitude dropped)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(vif_df.sort_values('VIF', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91112202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Performance metrics ─────────────────────────────────────────────────--\n",
    "train_r2 = r2_score(y_train, ols_model.predict(X_train_sm))\n",
    "test_r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(\"=== Model Performance ===\")\n",
    "print(f\"R² (train): {train_r2:.4f}\")\n",
    "print(f\"R² (test) : {test_r2:.4f}\")\n",
    "print(f\"RMSE (test): {rmse:,.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82430b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual vs Predicted comparison table\n",
    "\n",
    "compare_df = pd.DataFrame({\n",
    "    \"Actual\": y_test.reset_index(drop=True),\n",
    "    \"Predicted\": pd.Series(y_pred)\n",
    "})\n",
    "print(compare_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533f32f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy %\n",
    "\n",
    "accuracy_pct = compare_df.corr().iloc[0,1] * 100\n",
    "print(f\"Test-set accuracy ≈ {accuracy_pct:.1f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
